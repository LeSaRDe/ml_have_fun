{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "bde81360-ee70-46ff-bc56-10ceb2903b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We collect all needed modules here.\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef73698c-9fcb-4c31-b6cc-545c70e71883",
   "metadata": {},
   "source": [
    "# Task\n",
    "\n",
    "We want to determine the quality of a red/white wine. To do so, we will build a model based on some data with quality labels (which are ranks between 0 and 10). Each red/white wine is described by a list of attributes with values. The model will be built using supervised learning. In other words, we will train the model to make it match the ranks to the corresponding attribute values. The ultimate goal is that the model can correctly determine the rank given a new red/white wine with its attribute values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56285e9b-2bac-4ecf-aa0b-5e03cf886eee",
   "metadata": {},
   "source": [
    "# Data Source\n",
    "\n",
    "Download the data from UCI: https://archive.ics.uci.edu/dataset/186/wine+quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b832bd3d-fb37-4a8e-81c4-9940722a4cd5",
   "metadata": {},
   "source": [
    "# Data Profiling\n",
    "\n",
    "We would like to have some general ideas about the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "111ca50d-fd93-4c85-bf9d-55f3cf55a154",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 456K\n",
      "drwxrwxr-x 3 fmeng fmeng 4.0K Aug 25 23:42 .\n",
      "drwxrwxr-x 6 fmeng fmeng 4.0K Aug 25 22:45 ..\n",
      "drwxrwxr-x 2 fmeng fmeng 4.0K Aug 25 22:47 .ipynb_checkpoints\n",
      "-rw-rw-r-- 1 fmeng fmeng 2.4K Aug 25 23:42 ml_hands_on.ipynb\n",
      "-rwx------ 1 fmeng fmeng 3.3K May 22 22:24 winequality.names\n",
      "-rwx------ 1 fmeng fmeng  83K May 22 22:24 winequality-red.csv\n",
      "-rwx------ 1 fmeng fmeng 259K May 22 22:24 winequality-white.csv\n",
      "-rw-rw-r-- 1 fmeng fmeng  90K Aug 25 22:42 wine+quality.zip\n"
     ]
    }
   ],
   "source": [
    "# Let's take a look at the data files.\n",
    "! ls -ahl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6c693a4-cc22-41a8-a7d7-6c63fb4125a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"fixed acidity\";\"volatile acidity\";\"citric acid\";\"residual sugar\";\"chlorides\";\"free sulfur dioxide\";\"total sulfur dioxide\";\"density\";\"pH\";\"sulphates\";\"alcohol\";\"quality\"\n",
      "7.4;0.7;0;1.9;0.076;11;34;0.9978;3.51;0.56;9.4;5\n",
      "7.8;0.88;0;2.6;0.098;25;67;0.9968;3.2;0.68;9.8;5\n",
      "7.8;0.76;0.04;2.3;0.092;15;54;0.997;3.26;0.65;9.8;5\n",
      "11.2;0.28;0.56;1.9;0.075;17;60;0.998;3.16;0.58;9.8;6\n"
     ]
    }
   ],
   "source": [
    "# Read a few lines (5 lines in this example) of each CSV file to understand its format.\n",
    "! head -5 winequality-red.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dcc6a1d2-99db-427f-b7b2-46a6b4952d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"fixed acidity\";\"volatile acidity\";\"citric acid\";\"residual sugar\";\"chlorides\";\"free sulfur dioxide\";\"total sulfur dioxide\";\"density\";\"pH\";\"sulphates\";\"alcohol\";\"quality\"\n",
      "7;0.27;0.36;20.7;0.045;45;170;1.001;3;0.45;8.8;6\n",
      "6.3;0.3;0.34;1.6;0.049;14;132;0.994;3.3;0.49;9.5;6\n",
      "8.1;0.28;0.4;6.9;0.05;30;97;0.9951;3.26;0.44;10.1;6\n",
      "7.2;0.23;0.32;8.5;0.058;47;186;0.9956;3.19;0.4;9.9;6\n"
     ]
    }
   ],
   "source": [
    "! head -5 winequality-white.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f6f2da-f8a5-4673-9cc2-1b4746b50d44",
   "metadata": {},
   "source": [
    "- The first line of this CSV file is called the *\"header\"*. It specifies the column names. Though, a CSV file does not necessarily have the header. In other words, some CSV files simply start their data from the very first row.\n",
    "- The symbol \";\" is called the \"*separator*\" which separates columns. Various characters can be used as separators, such as \",\" and the tab character. Usually, we may have to view a few lines to tell which character is used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1076f3a-f91b-4008-8fe8-51ec827f4d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red Wine Data Profile:\n",
      " fixed acidity           float64\n",
      "volatile acidity        float64\n",
      "citric acid             float64\n",
      "residual sugar          float64\n",
      "chlorides               float64\n",
      "free sulfur dioxide     float64\n",
      "total sulfur dioxide    float64\n",
      "density                 float64\n",
      "pH                      float64\n",
      "sulphates               float64\n",
      "alcohol                 float64\n",
      "quality                   int64\n",
      "dtype: object\n",
      "Red Wine Data Profile:\n",
      "        fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
      "count    1599.000000       1599.000000  1599.000000     1599.000000   \n",
      "mean        8.319637          0.527821     0.270976        2.538806   \n",
      "std         1.741096          0.179060     0.194801        1.409928   \n",
      "min         4.600000          0.120000     0.000000        0.900000   \n",
      "25%         7.100000          0.390000     0.090000        1.900000   \n",
      "50%         7.900000          0.520000     0.260000        2.200000   \n",
      "75%         9.200000          0.640000     0.420000        2.600000   \n",
      "max        15.900000          1.580000     1.000000       15.500000   \n",
      "\n",
      "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
      "count  1599.000000          1599.000000           1599.000000  1599.000000   \n",
      "mean      0.087467            15.874922             46.467792     0.996747   \n",
      "std       0.047065            10.460157             32.895324     0.001887   \n",
      "min       0.012000             1.000000              6.000000     0.990070   \n",
      "25%       0.070000             7.000000             22.000000     0.995600   \n",
      "50%       0.079000            14.000000             38.000000     0.996750   \n",
      "75%       0.090000            21.000000             62.000000     0.997835   \n",
      "max       0.611000            72.000000            289.000000     1.003690   \n",
      "\n",
      "                pH    sulphates      alcohol      quality  \n",
      "count  1599.000000  1599.000000  1599.000000  1599.000000  \n",
      "mean      3.311113     0.658149    10.422983     5.636023  \n",
      "std       0.154386     0.169507     1.065668     0.807569  \n",
      "min       2.740000     0.330000     8.400000     3.000000  \n",
      "25%       3.210000     0.550000     9.500000     5.000000  \n",
      "50%       3.310000     0.620000    10.200000     6.000000  \n",
      "75%       3.400000     0.730000    11.100000     6.000000  \n",
      "max       4.010000     2.000000    14.900000     8.000000  \n"
     ]
    }
   ],
   "source": [
    "# Load the data into pandas DataFrame.\n",
    "df_red = pd.read_csv('winequality-red.csv', sep=';')\n",
    "# Check the type of each column.\n",
    "print('Red Wine Data Profile:\\n', df_red.dtypes)\n",
    "# Get some basic statistics.\n",
    "print('Red Wine Data Profile:\\n', df_red.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53624875-3cb6-4a58-b89b-34606f30bfd7",
   "metadata": {},
   "source": [
    "# Data Preparation for Machine Learning\n",
    "\n",
    "Typically, the raw dataset needs to be split to at least two subsets: *training set* and *test set*. The training set is used to actually train the model. And, the test set is used to evaluate how well the trained model performs. In some other cases, another subset is needed to tune the machine learning model, and usually we call it *validation set*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df947627-ccab-47eb-89ae-ece514a117c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train_set shape: (1071, 12)\n",
      "df_test_set shape: (528, 12)\n"
     ]
    }
   ],
   "source": [
    "# We use a friendly tool provided in scikit-learn to split the raw dataset. And, we use 2/3 of the raw data to do the training, and the rest to do the testing.\n",
    "df_train_set, df_test_set = train_test_split(df_red, test_size=0.33, shuffle=True)\n",
    "print('df_train_set shape:', df_train_set.shape)\n",
    "print('df_test_set shape:', df_test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "06cc126a-0d5d-48f9-8060-b3fe7f8a9ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nd_train_data shape: (1071, 11)\n",
      "nd_train_label shape: (1071,)\n",
      "nd_test_data shape: (528, 11)\n",
      "nd_test_label shape: (528,)\n"
     ]
    }
   ],
   "source": [
    "# To make our training and testing smoother, we need to separate the attributes from the quality ranks in each of the set obtained above. \n",
    "# And, instead of using pandas DataFrame, we use NumPy ndarray for convenience in training and testing.\n",
    "nd_train_data = df_train_set[df_train_set.columns.drop('quality')].to_numpy()\n",
    "print('nd_train_data shape:', nd_train_data.shape)\n",
    "nd_train_label = df_train_set['quality'].to_numpy()\n",
    "print('nd_train_label shape:', nd_train_label.shape)\n",
    "\n",
    "nd_test_data = df_test_set[df_test_set.columns.drop('quality')].to_numpy()\n",
    "print('nd_test_data shape:', nd_test_data.shape)\n",
    "nd_test_label = df_test_set['quality'].to_numpy()\n",
    "print('nd_test_label shape:', nd_test_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0f3c05-9e56-4b0d-ba92-a5b9fa011a8f",
   "metadata": {},
   "source": [
    "# Model Traning\n",
    "\n",
    "Without looking into the models, we simply treat them as blackboxes and train them using our training data. To help you gain better intuition, the model training can be roughly thought of as a procedure correlating the attribute values and the corresponding quality ranks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "09df73a5-f57b-40bb-9624-81aaa64d741a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainin score = 0.37929697168861665\n"
     ]
    }
   ],
   "source": [
    "# Model #1: Linear Regression\n",
    "\n",
    "# Create a Linear Regression model (not trained yet).\n",
    "lin_reg = linear_model.LinearRegression()\n",
    "# Train the model. And, the returned model is the trained model.\n",
    "lin_reg = lin_reg.fit(nd_train_data, nd_train_label)\n",
    "# Let's take a look at the score of training. In general, this scoring is based on the comparisons between the true labels and the predicted labels.\n",
    "# scikit-learn provides an algorithm of this scoring. When evaluating the performance of training, various scoring methods could be used. \n",
    "# Somehow, again, without looking into the technical details, we simply take the score value as a performance indicator. The best score is 1.0 indicating \n",
    "# a perfect performance of training. And, the lower, the worse, and it can be negative.\n",
    "train_score = lin_reg.score(nd_train_data, nd_train_label)\n",
    "print('Training score =', train_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560d7528-6be9-4e86-bee4-83ce566d7886",
   "metadata": {},
   "source": [
    "Uh...apparently, this score could hardly be said to be satisfactory. If one training trial doesn't convince you, let's try more. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e82b78c8-17bb-48ab-bc6a-33012cb81611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0: Trainin score = 0.3643187848639833\n",
      "Trial 1: Trainin score = 0.36255811694292706\n",
      "Trial 2: Trainin score = 0.3581940208959479\n",
      "Trial 3: Trainin score = 0.35500551220462784\n",
      "Trial 4: Trainin score = 0.358138525644185\n",
      "Trial 5: Trainin score = 0.3786575955890238\n",
      "Trial 6: Trainin score = 0.37330959136260955\n",
      "Trial 7: Trainin score = 0.34174201796686576\n",
      "Trial 8: Trainin score = 0.40638371829663955\n",
      "Trial 9: Trainin score = 0.34137025368697527\n",
      "Trial 10: Trainin score = 0.3581940208959479\n",
      "Trial 11: Trainin score = 0.36947686374578104\n",
      "Trial 12: Trainin score = 0.3664859480955972\n",
      "Trial 13: Trainin score = 0.366588847178843\n",
      "Trial 14: Trainin score = 0.3710474741250296\n",
      "Trial 15: Trainin score = 0.34686836213250016\n",
      "Trial 16: Trainin score = 0.3613472531914238\n",
      "Trial 17: Trainin score = 0.34148513800611\n",
      "Trial 18: Trainin score = 0.3890569979217604\n",
      "Trial 19: Trainin score = 0.3798295106446976\n",
      "Trial 20: Trainin score = 0.35500551220462784\n",
      "Trial 21: Trainin score = 0.3402303496975939\n",
      "Trial 22: Trainin score = 0.3687084547763114\n",
      "Trial 23: Trainin score = 0.3628349432892861\n",
      "Trial 24: Trainin score = 0.37386923979240316\n",
      "Trial 25: Trainin score = 0.37093318108544204\n",
      "Trial 26: Trainin score = 0.3672987332120923\n",
      "Trial 27: Trainin score = 0.3504680332659327\n",
      "Trial 28: Trainin score = 0.34148513800611\n",
      "Trial 29: Trainin score = 0.35478568480238637\n",
      "Trial 30: Trainin score = 0.3405121545545843\n",
      "Trial 31: Trainin score = 0.34312404107950034\n",
      "Trial 32: Trainin score = 0.3786575955890238\n",
      "Trial 33: Trainin score = 0.3500555102617904\n",
      "Trial 34: Trainin score = 0.36561569752491907\n",
      "Trial 35: Trainin score = 0.3426405054539239\n",
      "Trial 36: Trainin score = 0.35650661300677144\n",
      "Trial 37: Trainin score = 0.3659640532913936\n",
      "Trial 38: Trainin score = 0.361670247040604\n",
      "Trial 39: Trainin score = 0.37386923979240316\n",
      "Trial 40: Trainin score = 0.3548819315639009\n",
      "Trial 41: Trainin score = 0.33925043429827717\n",
      "Trial 42: Trainin score = 0.3405121545545843\n",
      "Trial 43: Trainin score = 0.3749458954535396\n",
      "Trial 44: Trainin score = 0.3708641690569201\n",
      "Trial 45: Trainin score = 0.3672987332120923\n",
      "Trial 46: Trainin score = 0.36561569752491907\n",
      "Trial 47: Trainin score = 0.34174201796686576\n",
      "Trial 48: Trainin score = 0.37325519650494043\n",
      "Trial 49: Trainin score = 0.3405121545545843\n"
     ]
    }
   ],
   "source": [
    "# We will shuffle the raw data and sample a training dataset for each trial.\n",
    "for i in range(50):\n",
    "    df_train_set_rand, df_test_set_rand = train_test_split(df_red, test_size=0.33, random_state=np.random.randint(low=1, high=100), shuffle=True)\n",
    "    nd_train_data_rand = df_train_set_rand[df_train_set_rand.columns.drop('quality')].to_numpy()\n",
    "    nd_train_label_rand = df_train_set_rand['quality'].to_numpy()\n",
    "    lin_reg_rand = linear_model.LinearRegression()\n",
    "    lin_reg_rand = lin_reg_rand.fit(nd_train_data_rand, nd_train_label_rand)\n",
    "    train_score = lin_reg_rand.score(nd_train_data_rand, nd_train_label_rand)\n",
    "    print('Trial %s: Trainin score = %s' % (i, train_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f821251-aa8b-4089-8bad-14d55453d023",
   "metadata": {},
   "source": [
    "After another 50 trials, it's sort of convining that the Linear Regression model, w.r.t. our current training strategy, may not work well. Though, we still want to see how the model would perform on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a69c29-e1ab-47f3-89f4-b243316e136c",
   "metadata": {},
   "source": [
    "# Model Testing\n",
    "\n",
    "In testing, we will use the other dataset split from the raw data. We cannot use the same dataset for both training and testing. It's cheating. This is because the trained model may only perform well on the training set but not quite on any other datasets. In other words, the model is useless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "0269da9e-543f-4f1e-8ea6-7c08fa19dba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_score = 0.3148494413210071\n"
     ]
    }
   ],
   "source": [
    "# We simply use the same scoring to evaluate the performance of the trained model on the test set.\n",
    "test_score = lin_reg.score(nd_test_data, nd_test_label)\n",
    "print('test_score =', test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fbfc07-7a39-4eed-9331-b54477bdb224",
   "metadata": {},
   "source": [
    "Without any surprise, the performance score on testing is not appealing. More importantly, it is different from the training score. And, usually, testing scores are lower, more or less, than the training scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a84c3d0-ffa1-4077-a141-a67f396d359e",
   "metadata": {},
   "source": [
    "# Try Other Models\n",
    "\n",
    "Linear Regression is not our only option. And, in practice, it's very common that some models don't work well no matter how hard you train them. A straightforward strategy in this case is to try some other models. On the other hand, it's important to note that a model failing to perform well on one problem doesn't necessarily imply its performance on others. There is a famous theorem called **No Free Lunch Theorem** roughly stating the fact that no model rules everything, only performs well in some cases while bad in others. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "14a75e98-3575-4466-a1a1-73c68527869f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score = 0.6619981325863679\n",
      "Testing score = 0.5909090909090909\n"
     ]
    }
   ],
   "source": [
    "# Let's try a neural network model, multi-layer perceptron. \n",
    "mlp = MLPClassifier(hidden_layer_sizes=(300, 500, 300), learning_rate='adaptive', solver='adam', \n",
    "                    random_state=np.random.randint(low=1, high=100), max_iter=2000)\n",
    "mlp = mlp.fit(nd_train_data, nd_train_label)\n",
    "train_score = mlp.score(nd_train_data, nd_train_label)\n",
    "print('Training score =', train_score)\n",
    "test_score = mlp.score(nd_test_data, nd_test_label)\n",
    "print('Testing score =', test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a264f09c-b07a-4c62-929a-7b105ee40c50",
   "metadata": {},
   "source": [
    "Hey~ much better! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "40806d34-0279-4258-a6f7-9055f59ccc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score = 0.9757236227824463\n",
      "Testing score = 0.5890151515151515\n"
     ]
    }
   ],
   "source": [
    "gp = GaussianProcessClassifier(random_state=np.random.randint(low=1, high=100), n_jobs=-1)\n",
    "gp = gp.fit(nd_train_data, nd_train_label)\n",
    "train_score = gp.score(nd_train_data, nd_train_label)\n",
    "print('Training score =', train_score)\n",
    "test_score = gp.score(nd_test_data, nd_test_label)\n",
    "print('Testing score =', test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "7b11123d-5f91-4ee7-ad17-b13e4657baa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score = 1.0\n",
      "Testing score = 0.6041666666666666\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=10, weights='distance', n_jobs=-1)\n",
    "knn = knn.fit(nd_train_data, nd_train_label)\n",
    "train_score = knn.score(nd_train_data, nd_train_label)\n",
    "print('Training score =', train_score)\n",
    "test_score = knn.score(nd_test_data, nd_test_label)\n",
    "print('Testing score =', test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "f3e6da92-a371-4b3d-ab0f-f28ba0177994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score = 0.715219421101774\n",
      "Testing score = 0.6041666666666666\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=6)\n",
    "dt = dt.fit(nd_train_data, nd_train_label)\n",
    "train_score = dt.score(nd_train_data, nd_train_label)\n",
    "print('Training score =', train_score)\n",
    "test_score = knn.score(nd_test_data, nd_test_label)\n",
    "print('Testing score =', test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "8d86fd4a-166c-423b-aeb1-269f3e70295b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score = 0.5602240896358543\n",
      "Testing score = 0.6041666666666666\n"
     ]
    }
   ],
   "source": [
    "ada = AdaBoostClassifier(n_estimators=10, random_state=np.random.randint(low=1, high=100))\n",
    "ada = ada.fit(nd_train_data, nd_train_label)\n",
    "train_score = ada.score(nd_train_data, nd_train_label)\n",
    "print('Training score =', train_score)\n",
    "test_score = knn.score(nd_test_data, nd_test_label)\n",
    "print('Testing score =', test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "4190661d-16f9-4682-98db-967ce102e5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score = 0.9598506069094305\n",
      "Testing score = 0.6041666666666666\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(max_depth=10, n_estimators=10, criterion='entropy', n_jobs=-1)\n",
    "rf = rf.fit(nd_train_data, nd_train_label)\n",
    "train_score = rf.score(nd_train_data, nd_train_label)\n",
    "print('Training score =', train_score)\n",
    "test_score = knn.score(nd_test_data, nd_test_label)\n",
    "print('Testing score =', test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "ce38347d-af32-4d84-aaf3-acd61f33c638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score = 0.5676937441643324\n",
      "Testing score = 0.6041666666666666\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb = gnb.fit(nd_train_data, nd_train_label)\n",
    "train_score = gnb.score(nd_train_data, nd_train_label)\n",
    "print('Training score =', train_score)\n",
    "test_score = knn.score(nd_test_data, nd_test_label)\n",
    "print('Testing score =', test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "04a7cd8c-3bc1-4346-9f5d-07a858277736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score = 0.9747899159663865\n",
      "Testing score = 0.6041666666666666\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(gamma=1)\n",
    "svm = svm.fit(nd_train_data, nd_train_label)\n",
    "train_score = svm.score(nd_train_data, nd_train_label)\n",
    "print('Training score =', train_score)\n",
    "test_score = knn.score(nd_test_data, nd_test_label)\n",
    "print('Testing score =', test_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
